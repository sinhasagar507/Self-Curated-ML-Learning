{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np #linear algebra\nimport pandas as pd #data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt #data visualization\nimport seaborn as sns  #data visualization\nfrom scipy import stats #stats library\nfrom pylab import rcParams\n\n\n#Matplotlib runtime(rc) configuration options\nrcParams['figure.figsize'] = 11, 9\n\n\n\n#Coerce warning issues\nimport warnings\nwarnings.filterwarnings('ignore')\n\n\n\n#importing time-based libraries\nimport time\nfrom datetime import time\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \n\n#Libraries for statistical visualization in time-series\nfrom statsmodels.tsa.stattools import adfuller\nfrom statsmodels.graphics.tsaplots import plot_acf, plot_pacf\nfrom statsmodels.tsa.seasonal import seasonal_decompose\nfrom statsmodels.tsa.statespace.sarimax import SARIMAX\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-07-02T16:24:04.817764Z","iopub.execute_input":"2022-07-02T16:24:04.818247Z","iopub.status.idle":"2022-07-02T16:24:06.180242Z","shell.execute_reply.started":"2022-07-02T16:24:04.818151Z","shell.execute_reply":"2022-07-02T16:24:06.179170Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"TO DO LIST\n- [x] Data Cleaning\n   - [x] Erroneous data types and value encoding \n- [x] Basic Statistical Analysis\n   - [x] Null Values \n   - [x] Duplicates and data types \n   - [x] Description and information \n- [ ] Date Time Based Analysis\n   - [ ] Origin of Timestamps - How are they generated?\n   - [ ] Time Interval - Regular or Ireegular\n   - [ ] Extracting Year, Month, Date and Day \n- [ ] Preliminary Visualization \n   - [ ] Analyze univariate plots(scatter plot, lag plots, histograms, KDE and boxplots) \n   - [ ] Heatmpas and Autcorrelation plots \n   - [ ] Analyze the data for different periods - upsampling or downsampling data - DOMAIN SPECIFIC question - ask that to yourself - THIS PART WILL ARRIVE IN DETAILED ANALYSIS section \n","metadata":{}},{"cell_type":"markdown","source":"**Manipulating time series data**","metadata":{}},{"cell_type":"code","source":"__author__ = \"Sagar Sinha\"\n__NOTEBOOK__ = \"Univariate Time Series Prediction\"","metadata":{"execution":{"iopub.status.busy":"2022-07-02T16:55:24.744175Z","iopub.execute_input":"2022-07-02T16:55:24.744615Z","iopub.status.idle":"2022-07-02T16:55:24.750231Z","shell.execute_reply.started":"2022-07-02T16:55:24.744583Z","shell.execute_reply":"2022-07-02T16:55:24.748944Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv(\"../input/sunspots/Sunspots.csv\", parse_dates=True, infer_datetime_format=True, skip_blank_lines=True) # Reading the dataset \ndata.drop(['Unnamed: 0'], axis=1, inplace=True)\ndata.columns = ['date', 'no_of_sunspots']","metadata":{"execution":{"iopub.status.busy":"2022-07-02T16:59:31.823734Z","iopub.execute_input":"2022-07-02T16:59:31.824088Z","iopub.status.idle":"2022-07-02T16:59:31.838121Z","shell.execute_reply.started":"2022-07-02T16:59:31.824059Z","shell.execute_reply":"2022-07-02T16:59:31.837022Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"print(data.isnull().sum())  # Check for null values\nprint(\"\\n\")\nprint(data.dtypes)","metadata":{"execution":{"iopub.status.busy":"2022-07-02T17:01:18.431352Z","iopub.execute_input":"2022-07-02T17:01:18.431746Z","iopub.status.idle":"2022-07-02T17:01:18.443098Z","shell.execute_reply.started":"2022-07-02T17:01:18.431712Z","shell.execute_reply":"2022-07-02T17:01:18.442058Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"markdown","source":"**The 'Date' column is of 'object' data type. It needs to be converted into the datetime format**","metadata":{}},{"cell_type":"code","source":"data['date'] = data['date'].astype('datetime64') # Type-casting ['date'] column to Pandas datetime format\ndata = data.drop_duplicates() # Removes all duplicate rows, if any ","metadata":{"execution":{"iopub.status.busy":"2022-07-02T17:06:02.029838Z","iopub.execute_input":"2022-07-02T17:06:02.030526Z","iopub.status.idle":"2022-07-02T17:06:02.043781Z","shell.execute_reply.started":"2022-07-02T17:06:02.030485Z","shell.execute_reply":"2022-07-02T17:06:02.042835Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"print(data.describe())\nprint()\nprint(data.info())","metadata":{"execution":{"iopub.status.busy":"2022-07-02T17:08:05.543347Z","iopub.execute_input":"2022-07-02T17:08:05.543756Z","iopub.status.idle":"2022-07-02T17:08:05.573973Z","shell.execute_reply.started":"2022-07-02T17:08:05.543721Z","shell.execute_reply":"2022-07-02T17:08:05.572514Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"markdown","source":"### Observations\nThe data is slightly positively skewed, as evident from the differences between mean and median","metadata":{}},{"cell_type":"code","source":"#Some of the resourceful methods are pd.to_datetime(convert data type to datettime), pd.asfreq(for resampling) and pd.date_range(a range of dates)\n#Typical time-series shifting may include - shifting or lagging values back or forward in time, getting the values for a given time period, and computing the percent change\n#over many number of periods","metadata":{"execution":{"iopub.status.busy":"2022-02-11T18:36:44.949073Z","iopub.execute_input":"2022-02-11T18:36:44.949672Z","iopub.status.idle":"2022-02-11T18:36:44.954898Z","shell.execute_reply.started":"2022-02-11T18:36:44.949615Z","shell.execute_reply":"2022-02-11T18:36:44.953689Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Reading in the data and basic formatting**","metadata":{}},{"cell_type":"code","source":"sunspots = pd.read_csv('https://raw.githubusercontent.com/jbrownlee/Datasets/master/monthly-sunspots.csv', sep=',', parse_dates=True)","metadata":{"execution":{"iopub.status.busy":"2022-02-11T18:36:44.956381Z","iopub.execute_input":"2022-02-11T18:36:44.957022Z","iopub.status.idle":"2022-02-11T18:36:45.584421Z","shell.execute_reply.started":"2022-02-11T18:36:44.956981Z","shell.execute_reply":"2022-02-11T18:36:45.583108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sunspots.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-11T18:36:45.585909Z","iopub.execute_input":"2022-02-11T18:36:45.586229Z","iopub.status.idle":"2022-02-11T18:36:45.620075Z","shell.execute_reply.started":"2022-02-11T18:36:45.586199Z","shell.execute_reply":"2022-02-11T18:36:45.61914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sunspots['Month'] = pd.to_datetime(sunspots['Month'])\nsunspots.set_index('Month')","metadata":{"execution":{"iopub.status.busy":"2022-02-11T18:36:45.624166Z","iopub.execute_input":"2022-02-11T18:36:45.624542Z","iopub.status.idle":"2022-02-11T18:36:45.647868Z","shell.execute_reply.started":"2022-02-11T18:36:45.624506Z","shell.execute_reply":"2022-02-11T18:36:45.646324Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sunspots.tail()","metadata":{"execution":{"iopub.status.busy":"2022-02-11T18:36:45.652289Z","iopub.execute_input":"2022-02-11T18:36:45.653178Z","iopub.status.idle":"2022-02-11T18:36:45.668579Z","shell.execute_reply.started":"2022-02-11T18:36:45.653119Z","shell.execute_reply":"2022-02-11T18:36:45.667436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualization of a time-series, and summary stats and diagnostics","metadata":{}},{"cell_type":"code","source":"med_value = sunspots['Sunspots'].median()\nquant_25 = sunspots['Sunspots'].quantile(0.25)\nquant_99 = sunspots['Sunspots'].quantile(0.99)","metadata":{"execution":{"iopub.status.busy":"2022-02-11T18:36:45.670323Z","iopub.execute_input":"2022-02-11T18:36:45.670648Z","iopub.status.idle":"2022-02-11T18:36:45.686613Z","shell.execute_reply.started":"2022-02-11T18:36:45.670618Z","shell.execute_reply":"2022-02-11T18:36:45.685731Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Setting up the style of background grid\nfig = plt.figure()\nplt.style.use('fivethirtyeight')\nax = sunspots['Sunspots'].plot(color='blue', fontsize=10, figsize=(10, 8))\n\n\n#A horizontal span \n#Also there are \nax.axvspan(quant_25, quant_99, color='green', alpha=0.3)\n\n#A vertical span\nax.axhspan(30, 150, color='red', alpha=0.3)","metadata":{"execution":{"iopub.status.busy":"2022-02-11T18:36:45.687863Z","iopub.execute_input":"2022-02-11T18:36:45.688391Z","iopub.status.idle":"2022-02-11T18:36:45.963048Z","shell.execute_reply.started":"2022-02-11T18:36:45.688347Z","shell.execute_reply":"2022-02-11T18:36:45.961363Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Checking if there are any null values\nsunspots.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-02-11T18:36:45.964909Z","iopub.execute_input":"2022-02-11T18:36:45.965318Z","iopub.status.idle":"2022-02-11T18:36:45.978448Z","shell.execute_reply.started":"2022-02-11T18:36:45.965284Z","shell.execute_reply":"2022-02-11T18:36:45.976736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There aren't any null values in the dataframe","metadata":{}},{"cell_type":"markdown","source":"**Window Functions:**\n1. Used to identify sub-periods, calculates sub-metrics of sub-periods.\n2. Rolling - same size and sliding\n3. Expanding - includes all previous values","metadata":{}},{"cell_type":"code","source":"#Setting the index back to datetime format\nsunspots = sunspots.set_index('Month')","metadata":{"execution":{"iopub.status.busy":"2022-02-11T18:36:45.980192Z","iopub.execute_input":"2022-02-11T18:36:45.980532Z","iopub.status.idle":"2022-02-11T18:36:45.990236Z","shell.execute_reply.started":"2022-02-11T18:36:45.9805Z","shell.execute_reply":"2022-02-11T18:36:45.989275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Rolling mean visualizations of some section of data, say from 1749 to 1753, unable to understand the concept\nsunSome_part = sunspots[1749 : 1753]\n\n\nsunSome_mean1 = sunSome_part.rolling(1).mean() #rolling mean for a single month\nsunSome_mean2 = sunSome_part.rolling(2).mean() #rolling mean for 2 consecutive months\nsunSome_mean3 = sunSome_part.rolling(3).mean() #rolling mean for a period of 3 months\n\n# ax = sunSome_mean1.plot()\n# ax.set_xlabel('Date')\n# ax.set_ylabel('Rolling Mean Variation')\n# ax.set_title('SPOT statistics')\n\nplt.style.use('fivethirtyeight')\nfig, ax = plt.subplots(1, figsize=(10, 5))\n\nax.plot(sunSome_mean1, sunSome_mean1.index, linewidth=2, markersize=12, color='green')\nax.plot(sunSome_mean2, sunSome_mean2.index, linewidth=2, markersize=12, color='blue')\nax.plot(sunSome_mean3, sunSome_mean3.index, linewidth=2, markersize=12, color='red')\n\nplt.title('Plotting out the rolling mean statistics')\nplt.xlabel('Susnpots Mean')\nplt.ylabel('Period')\nplt.legend(['1Day', '2Day', '3Day'])\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-11T18:36:45.992197Z","iopub.execute_input":"2022-02-11T18:36:45.993041Z","iopub.status.idle":"2022-02-11T18:36:46.306436Z","shell.execute_reply.started":"2022-02-11T18:36:45.992986Z","shell.execute_reply":"2022-02-11T18:36:46.305362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Let's plot a more compact representation of our data. Here we will be computing rolling avergae for a lagging period of 2 months, i.e, 60 days.\n#ma variable is for moving avergaes\nma = sunspots.rolling(window=2).mean()\nmstd = sunspots.rolling(window=2).std()\n\n#Adding the lower bound\nma['Lower'] = ma['Sunspots'] - (2 * mstd['Sunspots'])\n\n#Adding the upper bound\nma['Upper'] = ma['Sunspots'] + (2 * mstd['Sunspots'])\n\n#Plot the dataframe and set the labels\nplt.figure(figsize=(10, 5))\n\nax = ma.plot(linewidth=0.8, fontsize=6)\nplt.xlabel('Date')\nplt.ylabel('Number of sunspots')\nplt.xlabel('Date')\nplt.title('Rolling mean and variance of the number of sunspots over the given period of time')\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-11T18:36:46.308075Z","iopub.execute_input":"2022-02-11T18:36:46.308621Z","iopub.status.idle":"2022-02-11T18:36:46.816458Z","shell.execute_reply.started":"2022-02-11T18:36:46.308586Z","shell.execute_reply":"2022-02-11T18:36:46.814965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Plotting aggregate values of a time series**","metadata":{}},{"cell_type":"code","source":"#For our use-case, let's try to plot the aggregate values for the number of spots in the year 1750\nsunspots_1750 = sunspots.iloc[sunspots.index.year==1750, : ]\nindex_month = sunspots.index.month\nsunspots_1750_by_month = sunspots.groupby(index_month).Sunspots.mean()\n\nsunspots_1750_by_month.plot()\nplt.ylabel('Cases per month')\nplt.legend('Sunspots', loc='upper left')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-11T18:36:46.817775Z","iopub.execute_input":"2022-02-11T18:36:46.81832Z","iopub.status.idle":"2022-02-11T18:36:47.049802Z","shell.execute_reply.started":"2022-02-11T18:36:46.818272Z","shell.execute_reply":"2022-02-11T18:36:47.048557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Hence from the above visualization we can infer that the number of sunspots is at peak during the summer months,  which could be predetermindedly hypothesised.","metadata":{}},{"cell_type":"markdown","source":"Summarizing and plotting summary statistics","metadata":{}},{"cell_type":"code","source":"#Describing the dataframe\nprint(sunspots.describe())\n\n#Minmimum value\nprint(sunspots['Sunspots'].min())\n\n#Maximum value\nprint(sunspots['Sunspots'].max())","metadata":{"execution":{"iopub.status.busy":"2022-02-11T18:36:47.051346Z","iopub.execute_input":"2022-02-11T18:36:47.051791Z","iopub.status.idle":"2022-02-11T18:36:47.070581Z","shell.execute_reply.started":"2022-02-11T18:36:47.051758Z","shell.execute_reply":"2022-02-11T18:36:47.06934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Printing out the boxplot for visualizing summary statistics\nboxplot = sunspots.boxplot()","metadata":{"execution":{"iopub.status.busy":"2022-02-11T18:36:47.072279Z","iopub.execute_input":"2022-02-11T18:36:47.072813Z","iopub.status.idle":"2022-02-11T18:36:47.244358Z","shell.execute_reply.started":"2022-02-11T18:36:47.072777Z","shell.execute_reply":"2022-02-11T18:36:47.243007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sunspots_copy = sunspots.copy()\nsunspots_copy.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-11T18:36:47.245954Z","iopub.execute_input":"2022-02-11T18:36:47.246336Z","iopub.status.idle":"2022-02-11T18:36:47.261491Z","shell.execute_reply.started":"2022-02-11T18:36:47.246304Z","shell.execute_reply":"2022-02-11T18:36:47.260336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sunspots_copy.rename(columns={'Month':'Date'}, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-02-11T18:36:47.262657Z","iopub.execute_input":"2022-02-11T18:36:47.263051Z","iopub.status.idle":"2022-02-11T18:36:47.274472Z","shell.execute_reply.started":"2022-02-11T18:36:47.262975Z","shell.execute_reply":"2022-02-11T18:36:47.272864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Printing out the boxplot for visualizing summary statistics\nboxplot = sunspots_copy.boxplot()","metadata":{"execution":{"iopub.status.busy":"2022-02-11T18:36:47.275722Z","iopub.execute_input":"2022-02-11T18:36:47.276116Z","iopub.status.idle":"2022-02-11T18:36:47.441377Z","shell.execute_reply.started":"2022-02-11T18:36:47.27608Z","shell.execute_reply":"2022-02-11T18:36:47.439982Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#We observe there are outliers in the upper half of boxplot. Let's reassign the outlier values to be equal to the upper half of the boxplot.\nupper_perc = sunspots_copy['Sunspots'].quantile(0.75)\nlower_perc = sunspots_copy['Sunspots'].quantile(0.25)\n\nupper_limit = upper_perc + (3 * upper_perc)\nlower_limit = lower_perc - (3 * lower_perc)\n\nprint(upper_limit)\nprint(lower_limit)","metadata":{"execution":{"iopub.status.busy":"2022-02-11T18:36:47.443138Z","iopub.execute_input":"2022-02-11T18:36:47.443604Z","iopub.status.idle":"2022-02-11T18:36:47.456791Z","shell.execute_reply.started":"2022-02-11T18:36:47.443565Z","shell.execute_reply":"2022-02-11T18:36:47.455382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#If the value of skewness is above 1, then it means there exists a positive skewness.\nsunspots_copy['Sunspots'].skew()","metadata":{"execution":{"iopub.status.busy":"2022-02-11T18:36:47.459646Z","iopub.execute_input":"2022-02-11T18:36:47.460204Z","iopub.status.idle":"2022-02-11T18:36:47.470618Z","shell.execute_reply.started":"2022-02-11T18:36:47.460155Z","shell.execute_reply":"2022-02-11T18:36:47.469094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Histograms and Kernel Density Estimations(KDE):","metadata":{}},{"cell_type":"code","source":"sunspots['Sunspots'].plot(kind='hist', bins=100)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-11T18:36:47.473224Z","iopub.execute_input":"2022-02-11T18:36:47.473832Z","iopub.status.idle":"2022-02-11T18:36:47.852659Z","shell.execute_reply.started":"2022-02-11T18:36:47.473781Z","shell.execute_reply":"2022-02-11T18:36:47.851056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In practice, histograms can be a substandard method for assessing the distribution of your data because they can be strongly affected by the number of bins that have been specified. Instead, kernel density plots represent a more effective way to view the distribution of your data. An example of how to generate a density plot of is shown below:","metadata":{}},{"cell_type":"code","source":"ax = sunspots['Sunspots'].plot(kind='density', linewidth=2)","metadata":{"execution":{"iopub.status.busy":"2022-02-11T18:36:47.854216Z","iopub.execute_input":"2022-02-11T18:36:47.854562Z","iopub.status.idle":"2022-02-11T18:36:48.162765Z","shell.execute_reply.started":"2022-02-11T18:36:47.854529Z","shell.execute_reply":"2022-02-11T18:36:48.161527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Since the distribution isn't normal, we will perform the following the quantile-based imputation\n#sunspots_copy[sunspots_copy['Sunspots'] > upper_limit] = upper_limit","metadata":{"execution":{"iopub.status.busy":"2022-02-11T18:36:48.164773Z","iopub.execute_input":"2022-02-11T18:36:48.16533Z","iopub.status.idle":"2022-02-11T18:36:48.170544Z","shell.execute_reply.started":"2022-02-11T18:36:48.165292Z","shell.execute_reply":"2022-02-11T18:36:48.16872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#There are a lot of negative values in the dataset. We need to remove them for the transformation to happen\n#sunspots_copy['Sunspots-1'] = sunspots_copy[sunspots_copy['Sunspots'] > 0]","metadata":{"execution":{"iopub.status.busy":"2022-02-11T18:36:48.17322Z","iopub.execute_input":"2022-02-11T18:36:48.173794Z","iopub.status.idle":"2022-02-11T18:36:48.187149Z","shell.execute_reply.started":"2022-02-11T18:36:48.173741Z","shell.execute_reply":"2022-02-11T18:36:48.184986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Log-trasnform for removing left skewness\n#sunspots_copy['Sunspots-1'] = np.log1p(sunspots_copy['Sunspots-1'])","metadata":{"execution":{"iopub.status.busy":"2022-02-11T18:36:48.189346Z","iopub.execute_input":"2022-02-11T18:36:48.189942Z","iopub.status.idle":"2022-02-11T18:36:48.203258Z","shell.execute_reply.started":"2022-02-11T18:36:48.189862Z","shell.execute_reply":"2022-02-11T18:36:48.201525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#sunspots_copy['Sunspots-1'].plot(kind='hist', bins=100)\n#plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-11T18:36:48.205135Z","iopub.execute_input":"2022-02-11T18:36:48.205488Z","iopub.status.idle":"2022-02-11T18:36:48.216329Z","shell.execute_reply.started":"2022-02-11T18:36:48.205458Z","shell.execute_reply":"2022-02-11T18:36:48.21473Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#sunspots_copy.drop(['Sunspots'], axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-02-11T18:36:48.218247Z","iopub.execute_input":"2022-02-11T18:36:48.218942Z","iopub.status.idle":"2022-02-11T18:36:48.231158Z","shell.execute_reply.started":"2022-02-11T18:36:48.218858Z","shell.execute_reply":"2022-02-11T18:36:48.229533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#sunspots_copy['Sunspots-1'].plot(kind='kde')","metadata":{"execution":{"iopub.status.busy":"2022-02-11T18:36:48.232629Z","iopub.execute_input":"2022-02-11T18:36:48.23305Z","iopub.status.idle":"2022-02-11T18:36:48.24824Z","shell.execute_reply.started":"2022-02-11T18:36:48.233014Z","shell.execute_reply":"2022-02-11T18:36:48.246906Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Plotting autocorrelation and autocorrelation","metadata":{}},{"cell_type":"code","source":"#Plotting autocorrelation\n#Lags and alpha are the only important parameters in these plots\nfig = plot_acf(sunspots_copy['Sunspots'], lags=20)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-11T18:36:48.250874Z","iopub.execute_input":"2022-02-11T18:36:48.251428Z","iopub.status.idle":"2022-02-11T18:36:48.634366Z","shell.execute_reply.started":"2022-02-11T18:36:48.251379Z","shell.execute_reply":"2022-02-11T18:36:48.633438Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Plotting partial autocorrelation\n#Lags and alpha are the only important parameters in these plots\nfig = plot_pacf(sunspots_copy['Sunspots'], lags=20)","metadata":{"execution":{"iopub.status.busy":"2022-02-11T18:36:48.635593Z","iopub.execute_input":"2022-02-11T18:36:48.636095Z","iopub.status.idle":"2022-02-11T18:36:48.812735Z","shell.execute_reply.started":"2022-02-11T18:36:48.636046Z","shell.execute_reply":"2022-02-11T18:36:48.811731Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Like autocorrelation, the partial autocorrelation function also measures the correlation coefficient between a time series and a lagged version of itself. But\nthe main difference between the two is that PACF smoothens(lessens variations) the effect of lags beyond the ones explicitly mentioned.","metadata":{}},{"cell_type":"markdown","source":"**Time Series Decomposition** - for visualizing trend, seasonality and noise","metadata":{}},{"cell_type":"code","source":"rcParams['figure.figsize'] = 11, 9\n\ndecomposition = seasonal_decompose(sunspots['Sunspots'])\nfigure = decomposition.plot()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-11T18:36:48.814674Z","iopub.execute_input":"2022-02-11T18:36:48.815024Z","iopub.status.idle":"2022-02-11T18:36:49.476244Z","shell.execute_reply.started":"2022-02-11T18:36:48.81499Z","shell.execute_reply":"2022-02-11T18:36:49.474839Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(dir(decomposition))","metadata":{"execution":{"iopub.status.busy":"2022-02-11T18:36:49.482798Z","iopub.execute_input":"2022-02-11T18:36:49.483165Z","iopub.status.idle":"2022-02-11T18:36:49.489137Z","shell.execute_reply.started":"2022-02-11T18:36:49.483133Z","shell.execute_reply":"2022-02-11T18:36:49.487745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(decomposition.seasonal)","metadata":{"execution":{"iopub.status.busy":"2022-02-11T18:36:49.491718Z","iopub.execute_input":"2022-02-11T18:36:49.492199Z","iopub.status.idle":"2022-02-11T18:36:49.507017Z","shell.execute_reply.started":"2022-02-11T18:36:49.492163Z","shell.execute_reply":"2022-02-11T18:36:49.505977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Time Series decomposition is a powerful tool to reveal the structure in a time-series.","metadata":{}},{"cell_type":"code","source":"#A seasonal component(cyclic component) exists when a time-series is influenced by seasonal factors. \ndecomp_seasonal = decomposition.resid\nax = decomp_seasonal.plot(figsize=(14, 10))\nax.set_xlabel('Date')\nax.set_ylabel('Seasonality')\nax.set_title('Seasonal values of the time series')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-11T18:36:49.509438Z","iopub.execute_input":"2022-02-11T18:36:49.509996Z","iopub.status.idle":"2022-02-11T18:36:49.856702Z","shell.execute_reply.started":"2022-02-11T18:36:49.509937Z","shell.execute_reply":"2022-02-11T18:36:49.855371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"So far we have known:\n1. Visualize aggregates of time series data\n2. Extract statistical summaries\n3. Autocorrelation and Partial autocorrelation\n4. Time Series decomposition.","metadata":{}},{"cell_type":"markdown","source":"Multiple time-****series plots - refer the course","metadata":{}},{"cell_type":"markdown","source":"**Also you can print out the relationships between different time series data using heatmaps and clustered heatmaps.**\n1. Create facetted plots and graphs(using the pandas .plot function and setting up the layout of plots\n2. Set horiziontal/vertical lines/regions to specify/highlight some important year/date. This is ideal for a multiple time-series dataset.\n3. Aggregate plots are also ideal for a time-series dataset. (Monthly or yearly trends) alongwith bbox_to_anchor)\n4. Seasonal decomposition of multiple time-series togther.","metadata":{}},{"cell_type":"markdown","source":"Multiple time-series visualizations and code templates","metadata":{}},{"cell_type":"markdown","source":"> Time-Series Visualizations","metadata":{}},{"cell_type":"code","source":"# Plot all time series in the jobs DataFrame\n# ax = jobs.plot(colormap='Spectral', fontsize=6, linewidth=0.8)\n    \n# Set labels and legend\n# ax.set_xlabel('Date', fontsize=10)\n# ax.set_ylabel('Unemployment Rate', fontsize=10)\n# ax.set_title('Unemployment rate of U.S. workers by industry', fontsize=10)\n# ax.legend(loc='center left', bbox_to_anchor=(1.0, 0.5))\n# Annotate your plots with vertical lines\n# ax.axvline('2001-07-01', color='blue', linestyle='--', linewidth=0.8)\n# ax.axvline('2008-09-01', color='blue', linestyle='--', linewidth=0.8)\n\n# Show plot\n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-11T18:36:49.858846Z","iopub.execute_input":"2022-02-11T18:36:49.859246Z","iopub.status.idle":"2022-02-11T18:36:49.86464Z","shell.execute_reply.started":"2022-02-11T18:36:49.85921Z","shell.execute_reply":"2022-02-11T18:36:49.863365Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Extract the seasonal values for the decomposition of each time series\n# for ts in jobs_names:\n#     jobs_seasonal[ts] = jobs_decomp[ts].seasonal\n    \n# Create a DataFrame from the jobs_seasonal dictionary\n# seasonality_df = pd.DataFrame.from_dict(jobs_seasonal)\n\n# Remove the label for the index\n# seasonality_df.index.name = None\n\n# Create a faceted plot of the seasonality_df DataFrame\n# seasonality_df.plot(subplots=True,\n#                    layout=(4, 4),\n#                    sharey=False,\n#                    fontsize=2,\n#                    linewidth=0.3,\n#                    legend=False)\n\n# Show plot\n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-11T18:36:49.866442Z","iopub.execute_input":"2022-02-11T18:36:49.867099Z","iopub.status.idle":"2022-02-11T18:36:49.884467Z","shell.execute_reply.started":"2022-02-11T18:36:49.867053Z","shell.execute_reply":"2022-02-11T18:36:49.883065Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get correlation matrix of the seasonality_df DataFrame\n# seasonality_corr = seasonality_df.corr(method='spearman')\n\n# Customize the clustermap of the seasonality_corr correlation matrix\n# fig = sns.clustermap(seasonality_corr, annot=True, annot_kws={\"size\": 4}, linewidths=.4, figsize=(15, 10))\n# plt.setp(fig.ax_heatmap.yaxis.get_majorticklabels(), rotation=0)\n# plt.setp(fig.ax_heatmap.xaxis.get_majorticklabels(), rotation=90)\n# plt.show()\n\n# Print the correlation between the seasonalities of the Government and Education & Health industries\n# print(0.89)","metadata":{"execution":{"iopub.status.busy":"2022-02-11T18:36:49.88629Z","iopub.execute_input":"2022-02-11T18:36:49.887067Z","iopub.status.idle":"2022-02-11T18:36:49.899938Z","shell.execute_reply.started":"2022-02-11T18:36:49.887023Z","shell.execute_reply":"2022-02-11T18:36:49.89857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Unlabelling the indices\n#The packages to be used are pandas, numpy, statsmodels and scipy for linear regression.","metadata":{"execution":{"iopub.status.busy":"2022-02-11T18:36:49.901614Z","iopub.execute_input":"2022-02-11T18:36:49.902095Z","iopub.status.idle":"2022-02-11T18:36:49.916871Z","shell.execute_reply.started":"2022-02-11T18:36:49.902054Z","shell.execute_reply":"2022-02-11T18:36:49.915499Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Probable questions to be asked\n#1. Do I need to resaqmple in my use-case?\n#2. Do I need to apply percent changes in my use-case?\n#3. ","metadata":{"execution":{"iopub.status.busy":"2022-02-11T18:36:49.91871Z","iopub.execute_input":"2022-02-11T18:36:49.919447Z","iopub.status.idle":"2022-02-11T18:36:49.931996Z","shell.execute_reply.started":"2022-02-11T18:36:49.919395Z","shell.execute_reply":"2022-02-11T18:36:49.930979Z"},"trusted":true},"execution_count":null,"outputs":[]}]}