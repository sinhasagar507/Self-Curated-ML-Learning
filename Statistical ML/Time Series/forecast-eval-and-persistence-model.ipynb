{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-25T07:30:39.081164Z","iopub.execute_input":"2022-06-25T07:30:39.082343Z","iopub.status.idle":"2022-06-25T07:30:39.123372Z","shell.execute_reply.started":"2022-06-25T07:30:39.082176Z","shell.execute_reply":"2022-06-25T07:30:39.122184Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Forecast Error or Residual Forecast Error\nexpected = [0.0, 0.5, 0.0, 0.5, 0.0]\npredictions = [0.2, 0.4, 0.1, 0.6, 0.2]\nforecast_errors = [expected[i]-predictions[i] for i in range(len(expected))]\nprint('Forecast Errors: %s' % forecast_errors)\n\n## Mean Forecast Error or Forecast Bias \nexpected = [0.0, 0.5, 0.0, 0.5, 0.0]\npredictions = [0.2, 0.4, 0.1, 0.6, 0.2]\nforecast_errors = [expected[i]-predictions[i] for i in range(len(expected))]\nbias = sum(forecast_errors) * 1.0/len(expected)\nprint('Bias: %f' % bias)\n\n## MAE, MSE and RMSE ","metadata":{"execution":{"iopub.status.busy":"2022-06-25T07:30:39.125882Z","iopub.execute_input":"2022-06-25T07:30:39.126868Z","iopub.status.idle":"2022-06-25T07:30:39.138391Z","shell.execute_reply.started":"2022-06-25T07:30:39.126816Z","shell.execute_reply":"2022-06-25T07:30:39.136198Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Persistence Model for Forecasting \n## It is comprised of three steps - the TEST HARNESS\n## The dataset to be used to train and evaluate models\n## The resampling technique to be used to estimate the performance of the technique, i.e., train-test split \n## Performance measures, i.e MAE\n\n# Persistence models in TS = The simplest BASELINE model \n# A model that is SIMPLE, FAST and REPEATBALE = Provides deterministic outputs. Gives expected outputs for a given input ","metadata":{"execution":{"iopub.status.busy":"2022-06-25T07:30:39.141070Z","iopub.execute_input":"2022-06-25T07:30:39.142469Z","iopub.status.idle":"2022-06-25T07:30:39.148401Z","shell.execute_reply.started":"2022-06-25T07:30:39.142411Z","shell.execute_reply":"2022-06-25T07:30:39.147244Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"## Transform the univariate dataset into a supervised learning problem \n## Establish the train and test datasets for the test harness\n## Define the persistence model \n## Make a forecast and establish a performance baseline \n## Review example and plot the output ","metadata":{"execution":{"iopub.status.busy":"2022-06-25T07:30:39.151095Z","iopub.execute_input":"2022-06-25T07:30:39.152081Z","iopub.status.idle":"2022-06-25T07:30:39.160699Z","shell.execute_reply.started":"2022-06-25T07:30:39.152034Z","shell.execute_reply":"2022-06-25T07:30:39.159124Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"## Define the dataset \nseries = pd.read_csv('../input/shampoo-saled-dataset/shampoo_sales.csv', header=0, index_col=0, parse_dates=True, squeeze=True, on_bad_lines='skip')\ndataframe = pd.concat([series.shift(1), series], axis=1)\ndataframe.columns = ['t', 't+1']\ndataframe.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-25T07:30:39.162627Z","iopub.execute_input":"2022-06-25T07:30:39.163588Z","iopub.status.idle":"2022-06-25T07:30:39.215177Z","shell.execute_reply.started":"2022-06-25T07:30:39.163537Z","shell.execute_reply":"2022-06-25T07:30:39.214095Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"## Train and test sets \n## Split the dataset into training and test sets \nX = dataframe.values \ntrain_size = int(len(X) * 0.66)\ntrain, test = X[1:train_size], X[train_size:]\ntrain_X, train_y = train[:,0], train[:,1]\ntest_X, test_y = test[:,0], test[:,1]","metadata":{"execution":{"iopub.status.busy":"2022-06-25T07:30:39.217384Z","iopub.execute_input":"2022-06-25T07:30:39.217818Z","iopub.status.idle":"2022-06-25T07:30:39.224046Z","shell.execute_reply.started":"2022-06-25T07:30:39.217774Z","shell.execute_reply":"2022-06-25T07:30:39.222873Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Persistence Algorithm \ndef model_persistence(x):\n    return x","metadata":{"execution":{"iopub.status.busy":"2022-06-25T07:30:39.225675Z","iopub.execute_input":"2022-06-25T07:30:39.226802Z","iopub.status.idle":"2022-06-25T07:30:39.235640Z","shell.execute_reply.started":"2022-06-25T07:30:39.226754Z","shell.execute_reply":"2022-06-25T07:30:39.234856Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\n\n# Walk-Forward validation as we have incorporated the inputs from previous timesteps into the next one \npreds = []\nfor x in test_X:\n    yhat = model_persistence(x)\n    preds.append(yhat)\nrmse = np.sqrt(mean_squared_error(test_y, preds))\nprint('Test RMSE: %.3f' % rmse)","metadata":{"execution":{"iopub.status.busy":"2022-06-25T07:30:39.296615Z","iopub.execute_input":"2022-06-25T07:30:39.297300Z","iopub.status.idle":"2022-06-25T07:30:40.570275Z","shell.execute_reply.started":"2022-06-25T07:30:39.297265Z","shell.execute_reply":"2022-06-25T07:30:40.568891Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"test_X","metadata":{"execution":{"iopub.status.busy":"2022-06-25T07:30:40.572669Z","iopub.execute_input":"2022-06-25T07:30:40.573146Z","iopub.status.idle":"2022-06-25T07:30:40.581343Z","shell.execute_reply.started":"2022-06-25T07:30:40.573103Z","shell.execute_reply":"2022-06-25T07:30:40.579722Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Plotting the results of this model \nimport matplotlib.pyplot as plt \nplt.plot(train_y)\nplt.plot([None for i in train_y] + [target for target in test_y])\nplt.plot([None for i in train_y] + [pred for pred in preds])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-25T07:30:40.583311Z","iopub.execute_input":"2022-06-25T07:30:40.584078Z","iopub.status.idle":"2022-06-25T07:30:40.816531Z","shell.execute_reply.started":"2022-06-25T07:30:40.584035Z","shell.execute_reply":"2022-06-25T07:30:40.815704Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"# Visualizing Persistence Model Forecast ","metadata":{}},{"cell_type":"code","source":"# Create a lagged dataset \nvalues = pd.read_csv(\"../input/daily-total-female-births-in-california-1959/daily-total-female-births-CA.csv\", header=0, index_col=0, parse_dates=True, on_bad_lines='skip')\ndata = pd.concat([values.shift(1), values], axis=1)\ndata.columns = ['t', 't+1']\n\n# Remove data with NaN values\ndata = data.dropna()\n\n# Perform the splitting process\nX = data.values\ntrain_size = int(len(X) * 0.66)\ntrain_data, test_data = X[:train_size], X[train_size:]\nX_train, y_train = train_data[:, 0], train_data[:, 1]\nX_test, y_test = test_data[:, 0], test_data[:, 1]\n\n# Apply the persistence model \npreds = [x for x in X_test]\n\n# Capture residuals \nres = [y_test[i]- preds[i] for i in range(len(preds))]\n\n# Plot the residuals\nplt.subplot(211)\nplt.plot(res)\nplt.show()\n\n# Plot histogram \nplt.subplot(212)\nplt.hist(res)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-25T07:46:00.739174Z","iopub.execute_input":"2022-06-25T07:46:00.740301Z","iopub.status.idle":"2022-06-25T07:46:01.087556Z","shell.execute_reply.started":"2022-06-25T07:46:00.740244Z","shell.execute_reply":"2022-06-25T07:46:01.086082Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"# List summary statistics\nres = pd.DataFrame(res)\nprint(res.describe())\n\n# A naive form of bias correction would be to add residual errors to forecasts\n# But this method is naive, and it may not improve the model significantly ","metadata":{"execution":{"iopub.status.busy":"2022-06-25T07:48:14.429090Z","iopub.execute_input":"2022-06-25T07:48:14.429465Z","iopub.status.idle":"2022-06-25T07:48:14.447504Z","shell.execute_reply.started":"2022-06-25T07:48:14.429428Z","shell.execute_reply":"2022-06-25T07:48:14.446427Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"# Better ways to check for the randomness in plots \n# Plot line, KDE, histogram, QQ plpts and autocorrelation plots \nfrom pandas.plotting import autocorrelation_plot as ap\nap(res)\n\n# The autocorrelation values should be approaching zero, which is not the case for this set of residual errors\n# Hence, bias correction is required","metadata":{"execution":{"iopub.status.busy":"2022-06-25T07:56:41.768246Z","iopub.execute_input":"2022-06-25T07:56:41.768679Z","iopub.status.idle":"2022-06-25T07:56:41.989241Z","shell.execute_reply.started":"2022-06-25T07:56:41.768645Z","shell.execute_reply":"2022-06-25T07:56:41.987847Z"},"trusted":true},"execution_count":41,"outputs":[]}]}