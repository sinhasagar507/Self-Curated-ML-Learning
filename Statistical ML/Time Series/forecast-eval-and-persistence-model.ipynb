{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-23T14:37:35.883826Z","iopub.execute_input":"2022-06-23T14:37:35.884251Z","iopub.status.idle":"2022-06-23T14:37:35.891163Z","shell.execute_reply.started":"2022-06-23T14:37:35.884221Z","shell.execute_reply":"2022-06-23T14:37:35.889991Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Forecast Error or Residual Forecast Error\nexpected = [0.0, 0.5, 0.0, 0.5, 0.0]\npredictions = [0.2, 0.4, 0.1, 0.6, 0.2]\nforecast_errors = [expected[i]-predictions[i] for i in range(len(expected))]\nprint('Forecast Errors: %s' % forecast_errors)\n\n# Mean Forecast Error or Forecast Bias \nexpected = [0.0, 0.5, 0.0, 0.5, 0.0]\npredictions = [0.2, 0.4, 0.1, 0.6, 0.2]\nforecast_errors = [expected[i]-predictions[i] for i in range(len(expected))]\nbias = sum(forecast_errors) * 1.0/len(expected)\nprint('Bias: %f' % bias)\n\n# MAE, MSE and RMSE ","metadata":{"execution":{"iopub.status.busy":"2022-06-23T14:37:32.414862Z","iopub.execute_input":"2022-06-23T14:37:32.415315Z","iopub.status.idle":"2022-06-23T14:37:32.446205Z","shell.execute_reply.started":"2022-06-23T14:37:32.415233Z","shell.execute_reply":"2022-06-23T14:37:32.444992Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Persistence Model for Forecasting \n# It is comprised of three steps - the TEST HARNESS\n# The dataset to be used to train and evaluate models\n# The resampling technique to be used to estimate the performance of the technique, i.e., train-test split \n# Performance measures, i.e MAE\n\n# Persistence models in TS = The simplest BASELINE model \n# A model that is SIMPLE, FAST and REPEATBALE = Provides deterministic outputs. Gives expected outputs for a given input ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Transform the univariate dataset into a supervised leanring problem \n# Establish the train and test datasets for the test harness\n# Define the persistence model \n# Make a forecast and establish a performance baseline \n# Review example and plot the output ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the dataset \nseries = pd.read_csv('../input/shampoo-saled-dataset/shampoo_sales.csv', header=0, index_col=0, parse_dates=True, squeeze=True, on_bad_lines='skip')\ndataframe = pd.concat([series.shift(1), series], axis=1)\ndataframe.columns = ['t', 't+1']\ndataframe.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-23T14:59:15.992794Z","iopub.execute_input":"2022-06-23T14:59:15.993641Z","iopub.status.idle":"2022-06-23T14:59:16.018390Z","shell.execute_reply.started":"2022-06-23T14:59:15.993601Z","shell.execute_reply":"2022-06-23T14:59:16.017465Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Train and test sets \n# Split the dataset into training and test sets \nX = dataframe.values \ntrain_size = int(len(X) * 0.66)\ntrain, test = X[1:train_size], X[train_size:]\ntrain_X, train_y = train[:,0], train[:,1]\ntest_X, test_y = test[:,0], test[:,1]","metadata":{"execution":{"iopub.status.busy":"2022-06-23T15:04:07.968095Z","iopub.execute_input":"2022-06-23T15:04:07.968460Z","iopub.status.idle":"2022-06-23T15:04:07.975442Z","shell.execute_reply.started":"2022-06-23T15:04:07.968434Z","shell.execute_reply":"2022-06-23T15:04:07.974210Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Persistence Algorithm \ndef model_persistence(x):\n    return x","metadata":{"execution":{"iopub.status.busy":"2022-06-23T15:09:49.203315Z","iopub.execute_input":"2022-06-23T15:09:49.204003Z","iopub.status.idle":"2022-06-23T15:09:49.207883Z","shell.execute_reply.started":"2022-06-23T15:09:49.203966Z","shell.execute_reply":"2022-06-23T15:09:49.207121Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\n# Walk-Forward validation \npreds = []\nfor x in test_X:\n    yhat = model_persistence(x)\n    preds.append(yhat)\nrmse = np.sqrt(mean_squared_error(test_y, preds))\nprint('Test RMSE: %.3f' % rmse)","metadata":{"execution":{"iopub.status.busy":"2022-06-23T15:11:25.066420Z","iopub.execute_input":"2022-06-23T15:11:25.066841Z","iopub.status.idle":"2022-06-23T15:11:25.074351Z","shell.execute_reply.started":"2022-06-23T15:11:25.066807Z","shell.execute_reply":"2022-06-23T15:11:25.073377Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"test_X","metadata":{"execution":{"iopub.status.busy":"2022-06-23T15:16:04.023419Z","iopub.execute_input":"2022-06-23T15:16:04.023830Z","iopub.status.idle":"2022-06-23T15:16:04.030976Z","shell.execute_reply.started":"2022-06-23T15:16:04.023797Z","shell.execute_reply":"2022-06-23T15:16:04.030056Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"# Plotting the results of this model \nimport matplotlib.pyplot as plt \nplt.plot(train_y)\nplt.plot([None for i in train_y] + [target for target in test_y])\nplt.plot([None for i in train_y] + [pred for pred in preds])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-23T15:17:55.695206Z","iopub.execute_input":"2022-06-23T15:17:55.695587Z","iopub.status.idle":"2022-06-23T15:17:55.824825Z","shell.execute_reply.started":"2022-06-23T15:17:55.695558Z","shell.execute_reply":"2022-06-23T15:17:55.823703Z"},"trusted":true},"execution_count":32,"outputs":[]}]}