{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-25T07:29:35.185918Z","iopub.execute_input":"2022-06-25T07:29:35.186409Z","iopub.status.idle":"2022-06-25T07:29:35.234754Z","shell.execute_reply.started":"2022-06-25T07:29:35.186311Z","shell.execute_reply":"2022-06-25T07:29:35.233788Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Visualization libraries\nimport matplotlib.pyplot as plt\nimport seaborn as sns","metadata":{"execution":{"iopub.status.busy":"2022-06-25T07:29:35.236513Z","iopub.execute_input":"2022-06-25T07:29:35.237098Z","iopub.status.idle":"2022-06-25T07:29:36.633859Z","shell.execute_reply.started":"2022-06-25T07:29:35.237062Z","shell.execute_reply":"2022-06-25T07:29:36.632593Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Backtest Forecast Models","metadata":{}},{"cell_type":"code","source":"# The traditional splits and validation methods don't work in case of time series data, as they ignore the underlying temporal component \n# The temporal structure of data must be preserved \n# In the domain of timje series, the evaluation of models is called backtesting or hindcasting. \n# The train-test split method \n# Multiple train-test splits that respect the temporal order of observations\n# Walk-Forward validation scheme where a new model may be updated with each new time step as it is received ","metadata":{"execution":{"iopub.status.busy":"2022-06-25T07:29:36.635228Z","iopub.execute_input":"2022-06-25T07:29:36.636255Z","iopub.status.idle":"2022-06-25T07:29:36.642123Z","shell.execute_reply.started":"2022-06-25T07:29:36.636203Z","shell.execute_reply":"2022-06-25T07:29:36.640810Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"sunspots = pd.read_csv(\"../input/sunspots/Sunspots.csv\", header=0, index_col=0, parse_dates=True, squeeze=True)\nX = sunspots.values\ntrain_size = int(len(X) * 0.8)\ntrain, test = X[0:train_size], X[train_size:]\n# print(train.shape[0])\n# print(test.shape[0])\n\n\n# Plot the train and test sets together \nplt.plot([train[i][1] for i in range(len(train))])\nplt.plot([None for i in range(len(train))] + [test[i][1] for i in range(len(test))])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-25T07:29:36.644887Z","iopub.execute_input":"2022-06-25T07:29:36.645671Z","iopub.status.idle":"2022-06-25T07:29:36.933211Z","shell.execute_reply.started":"2022-06-25T07:29:36.645619Z","shell.execute_reply":"2022-06-25T07:29:36.931972Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Using the time-series split provided by Sklearn \n# Calculate the summary statistics used in multiple train-test splits \n# calculate repeated train-test splits of time series data\nfrom sklearn.model_selection import TimeSeriesSplit\nseries = pd.read_csv('../input/sunspots/Sunspots.csv', header=0, index_col=0, parse_dates=True, squeeze=True, on_bad_lines='skip')\nX = series.values\nsplits = TimeSeriesSplit(n_splits=3)\nplt.figure(1)\nindex = 1\n\nfor train_index, test_index in splits.split(X):\n    train = X[train_index]\n    test = X[test_index]\n    \n    print('Observations: %d' % (len(train) + len(test)))\n    print('Training Observations: %d' % (len(train)))\n    print('Testing Observations: %d' % (len(test)))\n    plt.subplot(310 + index)\n    plt.plot([train[i][1] for i in range(len(train))])\n    plt.plot([None for i in range(len(train))] + [test[i][1] for i in range(len(test))])\n    index += 1\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-25T07:29:36.935238Z","iopub.execute_input":"2022-06-25T07:29:36.935977Z","iopub.status.idle":"2022-06-25T07:29:37.699139Z","shell.execute_reply.started":"2022-06-25T07:29:36.935930Z","shell.execute_reply":"2022-06-25T07:29:37.697947Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# What usually happens above is that we our able to train different models, but just on historical data\n# If there is a workaround via which we can retrain the models by incorporating any nbew incoming instance of test data, tht would really be bebneficial\n# The same workaround is priovided by Walk Forward Validation","metadata":{"execution":{"iopub.status.busy":"2022-06-25T07:29:37.700834Z","iopub.execute_input":"2022-06-25T07:29:37.701328Z","iopub.status.idle":"2022-06-25T07:29:37.706692Z","shell.execute_reply.started":"2022-06-25T07:29:37.701283Z","shell.execute_reply":"2022-06-25T07:29:37.705335Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"**Steps needed to be followed while proceeding with the above mentioned Validation Technique**\n1. Select minimum no. of observations: First, we must select the minimum no. of observations required to train the model. This may be thought of window width if a sliding window is used. \n2. Sliding or Expanding Window: Next, it needs to be decided if the model will be trained on all data that is available or only on the most recetn observations. This determines whether a sliding or expanding window will be used. \n","metadata":{}},{"cell_type":"code","source":"# Currently, the facility isn't available with Sklearn, but the same can be availed by modifying the Time Series Split a little bit \n# Specify the number of training values \nn_train = 500\n\n# Specify the total number of records\nn_records = len(X)\n\nfor i in range(n_train, n_records):\n    train, test = X[0:i], X[i:i+1]\n    print('train=%d, test=%d' % (len(train), len(test)))","metadata":{"execution":{"iopub.status.busy":"2022-06-25T07:29:37.708196Z","iopub.execute_input":"2022-06-25T07:29:37.709347Z","iopub.status.idle":"2022-06-25T07:29:37.740938Z","shell.execute_reply.started":"2022-06-25T07:29:37.709299Z","shell.execute_reply":"2022-06-25T07:29:37.739216Z"},"trusted":true},"execution_count":7,"outputs":[]}]}